{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weidemaier/New Network\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "import trimesh\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import csv\n",
    "from utils import load_imf\n",
    "from trainers.utils.diff_ops import gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weidemaier/New Network/NFGP/logs/create_neural_fields_data.path=-home-weidemaier-NFGP-sphere2.npy_2024-Sep-21-16-59-11/checkpoints/epoch_99_iters_99400.pt\n",
      "Net:\n",
      "Net(\n",
      "  (blocks): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (5): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (act): Sine()\n",
      ")\n",
      "Scheduler Type: adaptive\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/weidemaier/New Network/NFGP/logs/create_neural_fields_data.path=-home-weidemaier-NFGP-sphere2.npy_2024-Sep-21-16-59-11\"\n",
    "\n",
    "net, cfg = load_imf(path, return_cfg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot slice of learned function (both for heat and 2nd step)\n",
    "\n",
    "sample_size = 100000\n",
    "\n",
    "linsp = np.linspace(-1.5, 1.5, 200)\n",
    "vec = [None]*200**2\n",
    "\n",
    "i = 0\n",
    "while i < 200:\n",
    "    k = 0\n",
    "    while k < 200:\n",
    "        ### if different slices should be considered, change here\n",
    "        vec[i*200 + k] = [0, linsp[i], linsp[k]]    \n",
    "        k = k+1\n",
    "    i = i+1\n",
    "\n",
    "xyz = torch.tensor(np.float32(vec)).cuda().requires_grad_(True)\n",
    "vec = net(xyz)\n",
    "grad = gradient(vec, xyz)\n",
    "norm_grad = grad.norm(p = 2, dim=-1).view(200**2, 1)\n",
    "normed = (grad/norm_grad).view(200**2, 3)\n",
    "\n",
    "a = vec.detach().cpu().numpy()\n",
    "A = xyz.detach().cpu().numpy()\n",
    "\n",
    "i = 0\n",
    "vec = [None]*200**2\n",
    "while i < 200**2:\n",
    "    vec[i] = [A[i, 1], A[i,2], a[i,0]]\n",
    "    i = i+1\n",
    "np.savetxt(\"plot_3d_new.csv\", vec , delimiter = \",\", header = \"x,y,z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for error estimation of learned SDF using input mesh\n",
    "from trimesh import proximity\n",
    "\n",
    "def err_mesh(net, mesh, bs):\n",
    "    normals = mesh.vertex_normals\n",
    "    \n",
    "    sample = trimesh.sample.sample_surface(mesh, bs)\n",
    "    points = sample[0]\n",
    "    coords = points\n",
    "    coords -= np.mean(coords, axis=0, keepdims=True)\n",
    "    keep_aspect_ratio = True\n",
    "    if keep_aspect_ratio:\n",
    "        coord_max = np.amax(coords)\n",
    "        coord_min = np.amin(coords)\n",
    "    else:\n",
    "        coord_max = np.amax(coords, axis=0, keepdims=True)\n",
    "        coord_min = np.amin(coords, axis=0, keepdims=True)\n",
    "    print((coord_max - coord_min))\n",
    "    coords = (coords - coord_min) / (coord_max - coord_min)\n",
    "    coords -= 0.5\n",
    "    coords *= 2.\n",
    "    points = coords\n",
    "    face_count = sample[1]\n",
    "    face_normals = mesh.face_normals\n",
    "    normals = face_normals[face_count]\n",
    "    mesh_prox = trimesh.proximity.ProximityQuery(mesh)\n",
    "    idx = np.random.randint(points.size/3, size=bs)\n",
    "    #B = points[idx,:]\n",
    "    #A = normals[idx,:]\n",
    "    #normals = A\n",
    "    points = np.float32(points)\n",
    "    points = torch.tensor(points)\n",
    "    points = points.cuda()\n",
    "    points.requires_grad = True\n",
    "    normals = np.float32(normals)\n",
    "    normals = torch.tensor(normals)\n",
    "    normals = normals.cuda()\n",
    "    normals.requires_grad = True\n",
    "    val = net(points)\n",
    "    \n",
    "\n",
    "    on_loss = abs(val).mean()\n",
    "    on_max = torch.max(abs(val))\n",
    "    #calc dists to mesh\n",
    "    r = np.random.uniform(0.15, 0.5, bs)\n",
    "    \n",
    "    phi = np.random.uniform(0, np.pi, bs)\n",
    "    theta = np.random.uniform(0, 2*np.pi, bs)\n",
    "    i = 0\n",
    "    random_points = [None]*bs\n",
    "    while (i < bs):\n",
    "        x = r[i]*np.sin(theta[i])*np.cos(phi[i])\n",
    "        y = r[i]*np.sin(theta[i])*np.sin(phi[i])\n",
    "        z = r[i]*np.cos(theta[i])\n",
    "        random_points[i] = [x,y,z]\n",
    "        i = i+1\n",
    "    \n",
    "    dist = proximity.closest_point(mesh, random_points)\n",
    "    dist = random_points - dist[0]\n",
    "    dist = np.linalg.norm(dist,axis=1)\n",
    "    \n",
    "    dist = np.float32(dist)\n",
    "    dist = torch.tensor(dist)\n",
    "    dist = dist.cuda()\n",
    "    dist.requires_grad = True\n",
    "    random_points = np.float32(random_points)\n",
    "    random_points = torch.tensor(random_points)\n",
    "    random_points = random_points.cuda()\n",
    "    random_points.requires_grad = True\n",
    "    val_off = net(random_points)\n",
    "    \n",
    "    \n",
    "    off_loss = abs(val_off - dist).mean()\n",
    "    off_max = torch.max(abs(val_off - dist))\n",
    "    grad = gradient(val, points).view(bs, 3)\n",
    "    l_normalized = grad/grad.norm(dim = -1).view(bs, 1)\n",
    "    sc_prod = l_normalized* (normals)\n",
    "    sc_prod = torch.sum(sc_prod.squeeze(), dim = 1)\n",
    "    sc_prod = torch.ones_like(sc_prod) + sc_prod\n",
    "    sc_max = torch.max(sc_prod)\n",
    "    sc_prod = torch.mean(sc_prod)\n",
    "    return on_loss.item(), on_max.item(), off_loss.item(), off_max.item(), sc_prod.item(), sc_max.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824763627984178\n",
      "(0.08867190033197403, 0.24954932928085327, 0.2713235318660736, 0.7658616900444031, 0.1041562408208847, 1.1373871564865112)\n"
     ]
    }
   ],
   "source": [
    "mesh = trimesh.load(\"/home/weidemaier/siren-master/rm_mid.obj\")\n",
    "print(err_mesh(net, mesh, 50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NFGP_w",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
